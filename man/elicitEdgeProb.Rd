% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/elicitEdgeProb.R
\name{elicitEdgeProb}
\alias{elicitEdgeProb}
\title{Elicit Prior Edge-Inclusion Probabilities with an LLM}
\usage{
elicitEdgeProb(
  context,
  variable_list,
  LLM_model = "gpt-5",
  update_key = FALSE,
  n_perm = NULL,
  seed = 123,
  main_prompt = NULL,
  display_progress = TRUE,
  logprobs = TRUE
)
}
\arguments{
\item{context}{Optional character string with study background or domain
context to incorporate into the prompt. Defaults to \code{NULL}.}

\item{variable_list}{Character vector of variable (node) names; must contain
at least three variables.}

\item{LLM_model}{Character string selecting the LLM. Options include
\code{"gpt-4o"}, \code{"gpt-4-turbo"}, \code{"gpt-3.5-turbo"}, \code{"gpt-5"}, \code{"gpt-5-mini"},
and \code{"gpt-5-nano"}.}

\item{update_key}{Logical; if \code{TRUE}, refreshes the API key prior to the LLM
call. Only the first call uses the updated key. Default is \code{FALSE}.}

\item{n_perm}{Integer or \code{NULL}. Number of random permutations of pair order
to evaluate. If \code{NULL}, five permutations are used by default. Maximum is
\code{50}.}

\item{seed}{Integer random seed for reproducibility of permutations.
Default is \code{123}.}

\item{main_prompt}{Optional length-1 character vector used as the LLM system
prompt. If \code{NULL}, a sensible default is used.}

\item{display_progress}{Logical; if \code{TRUE}, show progress messages.
Default is \code{TRUE}.}

\item{logprobs}{Logical; if \code{TRUE}, request token log-probabilities for the
first decision token. Ignored for models that do not support logprobs.
Default is \code{FALSE}.}
}
\value{
A list of class \code{"elicitEdgeProb"} with components:
\describe{
\item{relation_df}{Data frame with columns \code{var1}, \code{var2}, and \code{prob},
containing elicited prior probabilities of conditional associations.}
\item{raw_LLM}{Data frame of raw prompts, responses, and (when available)
token log-probabilities.}
\item{diagnostics}{List with counts and summary information about modes and
decision pathways used during elicitation.}
\item{inclusion_probability_matrix}{Symmetric matrix of edge-inclusion
probabilities suitable for a Bernoulli prior in \link[easybgm:easybgm]{easybgm}. Exact 0/1
values are squashed to \code{0.01}/\code{0.99}.}
\item{arguments}{List of input arguments for reproducibility.}
}
}
\description{
Queries a large language model (LLM) to elicit prior probabilities for the
presence of conditional associations (edges) between pairs of variables
(nodes) in a Markov random field (MRF) graphical model, as used for
psychological network models within the Bayesian Graphical Modeling (BGM)
framework. This is the main function of the package and it uses a chained
approach where in each permutation of all possible variable pairs,
the prompt for the current pair also includes the decisions made
for all previous pairs.
The output is useful for specifying prior inclusion probabilities in
the package \link[easybgm:easybgm]{easybgm} when using the Bernoulli prior.
The output from this function can also be used to
elicit the hyperparameters for the Beta-Bernoulli prior using the function
\code{betaBinParameters}. Or the expected number of clusters for the Stochastic
Block prior using the function \code{sbmClusters}.
}
\details{
The function iterates over all variable pairs and incrementally updates the
prompt so the LLM can condition each decision on prior decisions for other
pairs. To mitigate order effects, the pair order can be permuted multiple
times; elicited probabilities are then averaged across permutations.
The LLM is constrained to return binary decisions—\code{"I"} (include)
or \code{"E"} (exclude)—to facilitate stable probability elicitation.

When supported, token log-probabilities are requested and stored, enabling
downstream inspection of decision confidence. The final
\code{inclusion_probability_matrix} is symmetric and—where decisions imply exact
0/1—values are “squashed’’ to \code{0.01} and \code{0.99} to avoid degenerate priors in
BGM estimation software.
}
\examples{
\dontrun{
result <- elicitEdgeProb(
  context       = "Study on anxiety, sleep, and concentration.",
  variable_list = c("Anxiety", "Sleep", "Concentration"),
  LLM_model     = "gpt-4o",
  n_perm        = 2
)
print(result$relation_df)
}

}
\seealso{
\link[easybgm:easybgm]{easybgm}
}
